{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Books Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import string\n",
    "from sklearn import svm\n",
    "import seaborn as sns; \n",
    "import matplotlib.pyplot as plt \n",
    "import math\n",
    "import sys\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "import nltk\n",
    "from nltk.stem.isri import ISRIStemmer\n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "import unicodedata as ud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book ID</th>\n",
       "      <th>Book Name</th>\n",
       "      <th>Brif</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>كتابى الأول - الأعداد</td>\n",
       "      <td>أكثر الكتب نجاح ا مع الأطفال قبل عمر المدرسة ي...</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>حديقتي مدخل إلى لغتي</td>\n",
       "      <td>الغرض من هذه السلسلة أن يتعلّم الطالب ظبط الكل...</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>من أين تأتى الأشياء ؟</td>\n",
       "      <td>لقد صمم هذا الكتاب برسوماته الرقيقة وصوره الكب...</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>كتب الفراشة - سلسلة التليتبز؛ هدايا لطيفة \"كتا...</td>\n",
       "      <td>في يوم ما، وفي قرية التليتبي، تبادل التليتبز ه...</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>سلسلة مهارات الطالب: تدريبات في القراءة العربية</td>\n",
       "      <td>تشكل قراءة الأحرف وتعلمها واستخداماتها المختلف...</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Book ID                                          Book Name  \\\n",
       "0      1.0                              كتابى الأول - الأعداد   \n",
       "1      2.0                               حديقتي مدخل إلى لغتي   \n",
       "2      3.0                              من أين تأتى الأشياء ؟   \n",
       "3      4.0  كتب الفراشة - سلسلة التليتبز؛ هدايا لطيفة \"كتا...   \n",
       "4      5.0    سلسلة مهارات الطالب: تدريبات في القراءة العربية   \n",
       "\n",
       "                                                Brif Label  \n",
       "0  أكثر الكتب نجاح ا مع الأطفال قبل عمر المدرسة ي...     A  \n",
       "1  الغرض من هذه السلسلة أن يتعلّم الطالب ظبط الكل...     A  \n",
       "2  لقد صمم هذا الكتاب برسوماته الرقيقة وصوره الكب...     A  \n",
       "3  في يوم ما، وفي قرية التليتبي، تبادل التليتبز ه...     A  \n",
       "4  تشكل قراءة الأحرف وتعلمها واستخداماتها المختلف...     A  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_excel('datasets/ChildrenBooks300.xlsx', encoding ='utf-8-sig')\n",
    "dataset=dataset.dropna()\n",
    "dataset=dataset.reset_index(drop=True)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove colums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brif</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>أكثر الكتب نجاح ا مع الأطفال قبل عمر المدرسة ي...</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>الغرض من هذه السلسلة أن يتعلّم الطالب ظبط الكل...</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>لقد صمم هذا الكتاب برسوماته الرقيقة وصوره الكب...</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>في يوم ما، وفي قرية التليتبي، تبادل التليتبز ه...</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>تشكل قراءة الأحرف وتعلمها واستخداماتها المختلف...</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Brif Label\n",
       "0  أكثر الكتب نجاح ا مع الأطفال قبل عمر المدرسة ي...     A\n",
       "1  الغرض من هذه السلسلة أن يتعلّم الطالب ظبط الكل...     A\n",
       "2  لقد صمم هذا الكتاب برسوماته الرقيقة وصوره الكب...     A\n",
       "3  في يوم ما، وفي قرية التليتبي، تبادل التليتبز ه...     A\n",
       "4  تشكل قراءة الأحرف وتعلمها واستخداماتها المختلف...     A"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.drop(columns = {'Book ID', 'Book Name'})\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define features and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=dataset.iloc[:,0]\n",
    "y=dataset.iloc[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "arabic_diacritics = re.compile(\"\"\"\n",
    "                             ّ    | # Tashdid\n",
    "                             َ    | # Fatha\n",
    "                             ً    | # Tanwin Fath\n",
    "                             ُ    | # Damma\n",
    "                             ٌ    | # Tanwin Damm\n",
    "                             ِ    | # Kasra\n",
    "                             ٍ    | # Tanwin Kasr\n",
    "                             ْ    | # Sukun\n",
    "                             ـ     # Tatwil/Kashida\n",
    "                         \"\"\", re.VERBOSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize Arabic Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(len(x)):   \n",
    "    x[n] = re.sub(\"[إأآا]\", \"ا\", x[n])\n",
    "    x[n] = re.sub(\"ى\", \"ي\", x[n])\n",
    "    x[n] = re.sub(\"ؤ\", \"ء\", x[n])\n",
    "    x[n] = re.sub(\"ئ\", \"ء\", x[n])\n",
    "    x[n] = re.sub(\"ة\", \"ه\", x[n])\n",
    "    x[n] = re.sub(\"گ\", \"ك\", x[n])\n",
    "    x[n] = re.sub(\" ا \" ,\"\", x[n])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Arabic Diacritics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(len(x)):  \n",
    "    x[n] = re.sub(arabic_diacritics, '', x[n])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(len(x)): \n",
    "    x[n] = re.sub('[%s]' % re.escape(\"\"\"!\"#$%&'()*+,،-./:;<=>؟?@[\\]^_`{|}~\"\"\"), ' ', x[n])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(len(x)): \n",
    "    x[n] = re.sub('\\d+', '', x[n])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Extra whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(len(x)): \n",
    "    x[n] = re.sub('\\s+', ' ', x[n])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization and Remove Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('Arabic'))\n",
    "filtered_sentence = [] \n",
    "for n in range(len(x)):\n",
    "    word_tokens = nltk.word_tokenize(dataset['Brif'][n])\n",
    "    for w in word_tokens: \n",
    "        if w not in stop_words: \n",
    "            filtered_sentence.append(w) \n",
    "    filtered_sentenceD = TreebankWordDetokenizer().detokenize(filtered_sentence)\n",
    "    for c in filtered_sentenceD:\n",
    "        if ud.category(c).startswith(\"Po\"):\n",
    "            filtered_sentenceD = filtered_sentenceD.replace(c, '')\n",
    "    dataset['Brif'][n] = filtered_sentenceD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer=ISRIStemmer()\n",
    "X=x.to_dict()\n",
    "X=[]\n",
    "for d in range(len(x)):\n",
    "    b= stemmer.stem(x[d])\n",
    "    b=x[d].lower()\n",
    "    X.append(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [1, 1, 1, ..., 7, 1, 1],\n",
       "       [1, 1, 1, ..., 7, 1, 1],\n",
       "       [1, 1, 1, ..., 7, 1, 1]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect=CountVectorizer()\n",
    "a=count_vect.fit_transform(X)\n",
    "a.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00577144, 0.00550721, 0.00321862, ..., 0.01418554, 0.        ,\n",
       "        0.00289029],\n",
       "       [0.00583129, 0.00556433, 0.00325199, ..., 0.01433265, 0.        ,\n",
       "        0.00292026],\n",
       "       [0.        , 0.        , 0.00461007, ..., 0.01219089, 0.        ,\n",
       "        0.0041398 ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.00577546, ..., 0.01527265, 0.        ,\n",
       "        0.00518631],\n",
       "       [0.        , 0.        , 0.        , ..., 0.00952385, 0.        ,\n",
       "        0.00970237],\n",
       "       [0.        , 0.        , 0.00451539, ..., 0.01194052, 0.        ,\n",
       "        0.00405478]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect=CountVectorizer()\n",
    "X_train_counts=count_vect.fit_transform(X_train)\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_train_tfidf.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm=RandomOverSampler()\n",
    "X_train_res, y_train_res = sm.fit_sample(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform a grid search to find the optimal hyper-parameters and kernel function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# possible hyper-parameters and kernel\n",
    "#C_values = [0.01, 0.03, 0.1, 0.3, 1, 3, 10, 30, 100]\n",
    "#gamma_values = [0.01, 0.03, 0.1, 0.3, 1, 3, 10, 30, 100]\n",
    "#kernel_values = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "# accurcy\n",
    "#best_score = 0\n",
    "#best_params = {'C': None , 'kernel': None, 'gamma': None}\n",
    "#for C in C_values:\n",
    "#    for kernel in kernel_values:\n",
    "#        for gamma in gamma_values:\n",
    "        \n",
    "            # train the model for every hyper model\n",
    "#            svc = svm.SVC(C=C, kernel=kernel, gamma=gamma)\n",
    "#            svc.fit(X_train_res, y_train_res)\n",
    "#            score = svc.score (X_train_res, y_train_res)\n",
    "        \n",
    "            # rate accurcy of the prarmeters\n",
    "#            if score > best_score:\n",
    "#                best_score = score\n",
    "#                best_params['C'] = C\n",
    "#                best_params['kernel'] = kernel\n",
    "#                best_params['gamma'] = gamma\n",
    "#print best score\n",
    "#best_score, best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Buliding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf= svm.SVC(C=0.01, kernel = 'poly', gamma=7)\n",
    "clf.fit(X_train_res, y_train_res)\n",
    "clf.score(X_train_res, y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_tfidf=count_vect.transform(X_test)\n",
    "y_pred=clf.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "Accuracy_Score = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  =  100.0\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy  = ', Accuracy_Score * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the dataset with design boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'reduce_dim' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-44a831cc1912>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m.01\u001b[0m  \u001b[0;31m# step size in the mesh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_r\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreduce_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mX_train_r\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreduce_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mX_test_r\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreduce_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'reduce_dim' is not defined"
     ]
    }
   ],
   "source": [
    "h = .01  # step size in the mesh\n",
    "X_r = reduce_dim(X)\n",
    "X_train_r = reduce_dim(X_train)\n",
    "X_test_r = reduce_dim(X_test)\n",
    "\n",
    "figure = pl.figure(figsize=(15, 5))\n",
    "\n",
    "x_min, x_max = X_r[:, 0].min() - .5, X_r[:, 0].max() + .5\n",
    "y_min, y_max = X_r[:, 1].min() - .5, X_r[:, 1].max() + .5\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),np.arange(y_min, y_max, h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
